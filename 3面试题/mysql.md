# 基础

## MySQL有哪些数据类型
MySQL支持多种数据类型，这些数据类型用于定义表中的列的数据格式和限制。以下是一些常见的MySQL数据类型：
**1. 整数类型（Integer Types）：**
- `TINYINT`：范围为-128到127（有符号），0到255（无符号）的小整数。
- `SMALLINT`：范围为-32768到32767（有符号），0到65535（无符号）的较小整数。
- `MEDIUMINT`：范围为-8388608到8388607（有符号），0到16777215（无符号）的中等大小整数。
- `INT`：范围为-2147483648到2147483647（有符号），0到4294967295（无符号）的整数。
- `BIGINT`：范围为-9223372036854775808到9223372036854775807（有符号），0到18446744073709551615（无符号）的大整数。
**2. 浮点数和定点数类型（Floating-Point and Fixed-Point Types）：**
- `FLOAT`：单精度浮点数。
- `DOUBLE`：双精度浮点数。
- `DECIMAL`：精确的定点数，可指定小数点前后的位数。
**3. 字符串类型（String Types）：**
- `CHAR`：固定长度的字符，最多255个字符。
- `VARCHAR`：可变长度的字符，最多65535个字符。
- `TEXT`：长文本，最多65535个字符。
- `TINYTEXT`：短文本，最多255个字符。
- `MEDIUMTEXT`：中等长度文本，最多16777215个字符。
- `LONGTEXT`：非常长的文本，最多4294967295个字符。
**4. 日期和时间类型（Date and Time Types）：**
- `DATE`：日期，格式为'YYYY-MM-DD'。
- `TIME`：时间，格式为'HH:MM:SS'。
- `DATETIME`：日期和时间，格式为'YYYY-MM-DD HH:MM:SS'。
- `TIMESTAMP`：UNIX时间戳，通常以秒为单位存储。
- `YEAR`：年份，存储2位或4位年份。
**5. 二进制类型（Binary Types）：**
- `BINARY`：固定长度的二进制数据。
- `VARBINARY`：可变长度的二进制数据。
- `BLOB`：二进制大对象，用于存储二进制数据。
- `TINYBLOB`：短的二进制大对象。
- `MEDIUMBLOB`：中等长度的二进制大对象。
- `LONGBLOB`：非常长的二进制大对象。
**6. 枚举和集合类型（Enumeration and Set Types）：**
- `ENUM`：枚举类型，存储从预定义列表中选择的一个值。
- `SET`：集合类型，存储从预定义列表中选择的零个或多个值。
**7. 空间几何类型（Spatial Data Types）：**
- MySQL还支持空间数据类型，用于存储地理信息数据，如点、线、面等。
以上列出的数据类型是MySQL的一部分，不同版本的MySQL可能会有一些特定的扩展或变化。选择正确的数据类型取决于您的数据需求和数据库设计。
## CHAR，VARCHAR和Text 的区别
CHAR、VARCHAR和TEXT是MySQL中用于存储文本数据的不同数据类型，它们之间有以下主要区别：
1. **CHAR（定长字符串）**：
    - CHAR用于存储固定长度的字符串。
    - 您需要在定义字段时指定一个固定的字符长度，例如CHAR(10)表示存储一个长度为10的字符串。
    - 如果存储的字符串长度小于定义的长度，MySQL会在字符串后面添加空格以达到指定的长度。
    - CHAR适用于存储长度固定的数据，如邮政编码或国家/地区代码等。
2. **VARCHAR（可变长字符串）**：
    - VARCHAR用于存储可变长度的字符串。
    - 您需要在定义字段时指定最大字符长度，例如VARCHAR(255)表示最多可以存储255个字符的字符串。
    - 与CHAR不同，VARCHAR只会占用实际存储的字符数加上一些额外的存储空间来记录字符串的长度信息。
    - VARCHAR适用于存储长度可变的文本数据，如用户评论或文章内容。
3. **TEXT**：
    - TEXT用于存储大段文本数据，长度可变且可以非常大。
    - TEXT字段不需要指定最大长度，可以存储非常长的文本，最多可以存储65,535个字符（或更多，具体取决于MySQL配置）。
    - TEXT适用于存储较大的文本块，如文章正文、博客帖子或长篇评论。

主要区别总结如下：
- CHAR存储固定长度的字符串，而VARCHAR存储可变长度的字符串。
- CHAR会浪费存储空间，因为它填充额外的空格以达到指定长度，而VARCHAR只会占用实际字符长度加一些额外的存储空间。
- TEXT适用于存储大段文本数据，没有字符数限制，但可能会占用更多的存储空间。

您应该根据您的具体需求和数据特性来选择适当的数据类型。如果您知道数据长度是固定的，可以使用CHAR。如果长度可变或未知，而且文本较长，考虑使用VARCHAR或TEXT，取决于文本的最大长度。
## CHAR和VARCHAR如何选择
1. **如果数据长度是固定的**：
    - 如果您知道存储的数据长度始终是固定的，并且不会变化，那么可以选择使用CHAR。这可以提高检索性能，因为所有行的数据长度都相同，不需要额外的长度信息。
2. **如果数据长度是可变的**：
    - 如果您的数据长度是可变的，例如用户评论、文章内容或电子邮件正文等，通常应选择VARCHAR。VARCHAR会根据实际数据长度来分配存储空间，从而节省存储空间，特别是对于较长的文本字段。
3. **考虑存储效率**：
    - 如果您关注存储效率和节省存储空间，特别是在大型数据表中，VARCHAR通常更为节省空间，因为它只存储实际字符长度，而不会填充额外的空格。
4. **索引和检索性能**：
    - CHAR字段的固定长度可以提高某些查询的性能，因为它们允许数据库优化器更容易地进行索引操作。对于经常进行精确匹配的查询，CHAR可能更适合。
    - VARCHAR字段可能在模糊搜索（例如LIKE操作）方面更具性能，因为它们只存储实际字符长度，不会浪费时间在填充的空格上。
5. **多语言支持**：
    - 如果您需要存储多语言文本，考虑使用UTF-8字符集，并确保字段的长度足够容纳不同语言的字符。VARCHAR通常更适合存储多语言文本，因为不同语言的字符长度可能不同。

总之，CHAR适用于固定长度的数据，对于长度可变的文本数据，VARCHAR通常更为合适。并且通常char的精确查询性能更高，但是varchar的存储效率更高
## 什么是三大范式
三大范式是关系数据库设计中的规范，旨在确保数据库表的结构优化，减少数据冗余和提高数据的一致性。以下是三大范式的简要说明：
1. **第一范式（1NF）**：（无重复列）
    - 第一范式要求数据库表中的每个列都包含原子性数据，也就是说，**每个列中的值都是不可再分的**。
    - 1NF确保了数据的原子性，防止在一个列中存储多个值，从而使数据更容易管理和查询。
2. **第二范式（2NF）**：（存在主键）
    - 第二范式建立在第一范式的基础上，要求表中的**每个非主键列完全依赖于主键**。
    - 换句话说，如果一个表具有复合主键（多个列组成主键），那么每个非主键列必须与整个复合主键相关，而不是与部分主键相关。
    - 2NF消除了部分依赖，确保数据表的结构更清晰。
3. **第三范式（3NF）**： （非主属性互不依赖）
    - 第三范式要求表中的每个非主键列不依赖于其他非主键列。
    - 换句话说，如果一个非主键列依赖于另一个非主键列，那么应将其分解成独立的表，并建立适当的关系。
    - 3NF有助于消除传递性依赖，确保数据表的更高一致性。

三大范式有助于减少数据冗余，提高数据的完整性和一致性，并使数据库更容易维护和查询。然而，需要注意的是，并非所有情况都需要满足三大范式，有时会根据具体需求和性能考虑而允许违反其中一个或多个范式。在数据库设计中，需要权衡范式的要求和性能需求来做出最合适的设计决策。
## 什么是范式和反范式，以及各自优缺点
范式（Normalization）和反范式（Denormalization）是关系数据库设计中的两种不同方法，用于组织和管理数据表的结构。它们各自具有一些优点和缺点，根据具体情况选择使用。
**范式（Normalization）**：
范式是一种数据库设计方法，旨在减少数据冗余和提高数据的一致性。它包括一系列规则，如第一范式（1NF）、第二范式（2NF）、第三范式（3NF）等，以确保数据表的结构满足特定的标准。
**优点**：
1. **数据一致性：** 范式可以确保数据表中的数据非常一致，不会存在不一致的情况，因为数据没有重复。
2. **节省存储空间：** 范式通常会减少数据冗余，从而节省存储空间。
3. **数据更新容易：** 由于数据没有重复，因此在更新数据时只需要更新一个地方，而不是多个地方。
**缺点**：
1. **查询性能下降：** 范式化的表结构可能需要多个表之间的连接操作，这可能会导致查询性能下降，尤其是在复杂查询情况下。
2. **复杂性增加：** 范式化的设计可能需要更多的表和关系，使数据库结构变得更加复杂。

**反范式（Denormalization）**：
反范式是一种数据库设计方法，与范式相反，它通过增加冗余数据以提高查询性能和简化查询操作。在反范式设计中，通常会将数据冗余存储在表中，以减少连接操作和提高查询速度。
**优点**：
1. **查询性能提高：** 反范式可以显著提高查询性能，因为它减少了连接操作，并允许更简单的查询。
2. **简化查询：** 反范式化的设计可以使查询操作更加简单和直观。
**缺点**：
1. **数据冗余：** 反范式化通常会导致数据冗余，因为相同的数据可能存储在多个地方，这可能导致数据不一致的问题。
2. **更新复杂性：** 由于数据冗余，更新数据时可能需要更新多个地方，这增加了数据的维护复杂性。
3. **占用存储空间：** 反范式化可能占用更多的存储空间，因为数据重复存储。

选择范式化还是反范式化取决于具体的需求和权衡。通常情况下，范式化适用于数据一致性和规范性要求非常高的场景，而反范式化适用于需要快速查询和性能优化的场景。在设计数据库时，需要根据实际情况综合考虑这两种方法的优缺点，并根据优先级做出决策。有时也可以采用混合的方法，部分范式化和部分反范式化，以平衡数据一致性和查询性能。
# 索引

## 索引的优缺点
**优点**：
1. **提高检索速度**：
    - 最明显的优点是加速数据检索。索引允许数据库系统更快地定位和访问符合查询条件的数据行，特别是在大型数据表中，查询性能得到显著提升。
2. **支持快速查找**：
    - 索引使数据库系统能够在常数时间内快速查找特定值，而不是遍历整个数据表。
3. **排序优化**：
    - 索引可以提高排序操作的性能，因为数据库可以使用索引按顺序访问数据。
4. 加速连接操作：
    - 当执行连接操作（例如JOIN）时，索引可以加速数据的匹配过程，提高关联查询的性能。
5. 帮助确保数据完整性：
    - 唯一索引可以确保索引列中的数据唯一性，有助于维护数据完整性。

**缺点**：
1. **存储开销**：
    - 索引占用额外的存储空间，因为索引数据结构需要额外的内存和磁盘空间。对于大型数据表，索引可以占据相当大的空间。
2. **更新性能降低**：
    - 当插入、更新或删除数据行时，索引需要维护，这可能会导致更新性能下降。每次更新都需要更新索引结构，这会增加写操作的开销。
3. **查询性能下降（部分情况）**：
    - 在某些情况下，使用不当的索引或过多的索引可以导致查询性能下降。过多的索引可能会导致查询优化器选择错误的索引，增加了查询的成本。
4. 维护成本：
    - 数据库维护索引需要额外的工作，包括创建、重新构建和优化索引。这些操作可能会增加数据库管理员的工作负担。
5. 空间复杂性：
    - 对于复杂的查询，涉及多个表和多个索引时，查询优化可能变得复杂，不容易预测性能。

## 索引设计原则
1．**选择唯一性索引**
唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。
主键索引和唯一键索引，在查询中使用是效率最高的。
2．**为经常需要排序、分组和联合操作的字段建立索引**
经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。
如果为其建立索引，可以有效地避免排序操作。
3．**为常作为查询条件的字段建立索引**
如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。
4．尽量使用前缀来索引
如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。
5．限制索引的数目
索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。
修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。
6．尽量使用数据量少的索引
尽量使用字段长度小的列创建索引。
如果索引的值很长，那么查询的速度会受到影响。
7．删除不再使用或者很少使用的索引
表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。
## 索引的数据结构（索引的分类）
索引是数据库中用于提高数据检索速度的重要工具。根据其实现方式和用途，可以将索引分为多种类型或分类，以下是一些常见的索引类型（**数据结构一般指二叉树、红黑树、B树、B+树、哈希等**）：
1. **B-Tree 索引**：
    - B-Tree（平衡树）索引是最常见的数据库索引类型。
    - 它适用于大多数情况，支持等值查询、范围查询和排序操作。
    - B-Tree索引对于静态和动态数据都很有效，适用于大多数关系型数据库系统。
2. **B+Tree 索引**：
    - B+Tree索引是B-Tree的变种，常用于关系型数据库系统。
    - 与B-Tree不同，B+Tree索引中只包含叶子节点，内部节点只用于导航，这使得B+Tree索引更适合范围查询和排序操作。
3. **哈希索引**：
    - 哈希索引使用散列函数将索引键映射到存储桶（存储位置），通常用于等值查询。
    - 哈希索引对于等值查询非常高效，但不支持范围查询和排序操作。
    - 哈希索引在某些情况下可以提供非常快的查询性能，但不适用于所有场景。
4. **全文索引**：
    - 全文索引用于搜索文本数据，如文章、博客帖子或文档。
    - 它支持文本内容的关键字搜索，允许模糊查询和全文搜索。
    - 全文索引通常用于全文搜索引擎或数据库系统的全文搜索功能。
5. 空间索引：
    - 空间索引用于地理信息系统（GIS）或具有空间数据的应用程序。
    - 它支持地理空间数据类型，允许查询地理位置信息，如点、线、多边形等。
    - 常见的空间索引包括R-Tree和Quad-Tree。
6. 位图索引：
    - 位图索引使用位图（Bit Map）来表示索引键的值，通常用于低基数（不同值较少）的列。
    - 它非常适合于精确匹配查询，但对于高基数列（不同值较多）不太有效。
7. 覆盖索引：
    - 覆盖索引包括查询所需的所有列，无需回到原始数据表中检索数据。
    - 它可以提高查询性能，减少I/O操作，特别适用于查询选择性很高的情况。
8. **唯一索引**：
    - 唯一索引要求索引列的值必须是唯一的，通常用于确保数据表中的某一列没有重复值。
9. **复合索引**：
    - 复合索引是包含多个列的索引，可以用于同时查询这些列的条件。
    - 它可以提高多列查询的性能，但需要注意索引的顺序和查询条件的匹配度。
## Hash和B+树索引的区别?
哈希索引和B+树索引是两种不同的索引结构，它们在数据库中用于加速数据检索，具有一些关键区别：
**1. 数据结构：**
- **哈希索引：** 哈希索引使用哈希函数将索引键映射到存储桶（或槽位）中。每个存储桶可以包含一个或多个具有相同哈希值的索引键。哈希索引将索引键与存储桶之间的关系存储在内存中或磁盘上。
- **B+树索引：** B+树索引是一种树状结构，通常是平衡树，包括根节点、内部节点和叶子节点。叶子节点包含了实际的索引键和指向数据行的指针。B+树索引的内部节点用于导航和范围查询。
**2. 支持的查询类型：**
- **哈希索引：** 哈希索引主要适用于等值查询，即查找具有特定键值的行。哈希索引不支持范围查询和排序操作，因为它将键映射到离散的存储桶中，无法提供有序的数据访问。
- **B+树索引：** B+树索引支持等值查询、范围查询和排序操作。它可以在树结构中按照键值的顺序访问数据，因此非常适合各种查询类型。
**3. 存储和空间需求：**
- **哈希索引：** 哈希索引通常需要相对较小的存储空间，因为它将键映射到存储桶，但需要注意，存储桶的数量可能会影响性能。
- **B+树索引：** B+树索引通常需要更多的存储空间，因为它包含了更多的数据结构，包括内部节点和叶子节点。但由于其平衡树结构，它能够提供高效的范围查询和排序操作。
**4. 写操作的性能：**
- **哈希索引：** 哈希索引对于等值查询的写操作（插入、更新、删除）通常非常高效，因为它可以在常数时间内找到特定键值。但对于范围删除或更新操作，哈希索引可能需要扫描整个索引，性能较差。
- **B+树索引：** B+树索引对于等值查询和范围查询的写操作都相对高效，因为它的平衡树结构允许根据键值顺序访问数据。

总结来说，哈希索引适用于等值查询，具有快速的等值查询性能和较小的存储开销。而B+树索引更通用，适用于各种查询类型，包括等值查询、范围查询和排序操作，但通常需要更多的存储空间。
## 为何使用B+树而非二叉查找树做索引
在数据库系统中，通常使用B+树而不是普通的二叉查找树（Binary Search Tree，BST）来实现索引的主要原因有以下几点：
1. **平衡性和稳定性：**
    - B+树是一种自平衡树结构，而二叉查找树的平衡性不如B+树好。B+树的平衡性保证了在插入和删除操作后，树的高度保持相对稳定，从而保持了查询性能的稳定性。而BST的不平衡性可能会导致树的高度大幅增加，从而降低查询性能。
2. **范围查询的效率：**
    - B+树非常适合范围查询，因为它的叶子节点构成了一个有序链表，可以轻松执行范围查询操作。而BST需要在不同分支上进行搜索，效率相对较低。
3. **提高磁盘io效率（顺序读取）：**
    - B+树的节点通常比BST的节点大，因为它需要存储更多的键值对信息。然而，在磁盘上，顺序读取比随机读取更高效。由于B+树的有序性，磁盘IO更加连续，减少了随机读取，从而提高了磁盘IO效率。
4. **叶子节点的存储（所有数据都存储在叶子节点上）：**
    - B+树的叶子节点包含了所有索引数据，而内部节点仅包含索引键和指向子节点的指针。这样的设计使得B+树的叶子节点更适合内存缓存，因为它们通常更小，可以容纳更多的数据。相比之下，BST的所有节点都可能包含数据，会导致内存开销较大。
5. **支持高度扇出（每个节点可以有多个子节点）：**
    - B+树支持高度扇出（每个节点有多个子节点），这意味着在相对较低的高度下可以容纳大量数据。这对于大型数据库非常重要，因为它可以减少磁盘IO和提高查询性能。

## 为何使用B+树而非B树做索引
上述二叉查找树的平衡性考虑换为内存缓存即可
**更适合内存缓存：**
- B+树的叶子节点通常更小，因为它们只包含数据的引用（通常是行的ID或物理存储位置），这使得它们更适合内存缓存。相比之下，B树的非叶子节点也包含数据，会增加内存开销。

## 什么是最左匹配原则?
最左匹配原则是数据库索引优化的一个关键概念，它指导数据库系统在使用复合索引（Composite Index）时如何有效地匹配查询条件。
在最左匹配原则中，索引的复合键（Composite Key）中的多个列按照索引定义的顺序依次匹配查询条件。具体来说，当执行一个查询，涉及到复合索引的多个列时，数据库系统会首先使用索引的最左边的列来过滤数据，然后再逐渐向右匹配更多的列，直到满足查询条件或者不再匹配。
这个原则的关键在于，如果查询条件中涉及到复合索引的多个列，那么只有在最左边的列被用于查询时，索引才会发挥作用。如果最左边的列不在查询条件中，那么索引将无法有效利用。

举个例子，假设有一个复合索引 (A, B, C)，按照最左匹配原则：
1. 如果查询条件包括 A，那么索引可以被充分利用。
2. 如果查询条件包括 A 和 B，那么索引也可以被充分利用。
3. 如果查询条件包括 A、B 和 C，那么索引仍然可以被充分利用。
4. 但如果查询条件只包括 B 或者 C，而不包括 A，那么索引将无法有效使用。
5. 其余情况下（A,C），只有A能走索引而C无法走索引
## 聚簇索引和非聚簇索引
在 B+ 树的索引中，叶子节点可能存储了当前的键值，也可能存储了当前的键值以及整行的数据，这就是聚簇索引和非聚簇索引。 在 InnoDB 中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。
当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。
## 什么是覆盖索引
覆盖索引（Covering Index）是一种特殊类型的数据库索引，它包含了查询所需的所有列，而不仅仅是索引键列。当一个查询可以完全通过索引本身满足，而不需要访问实际数据表中的数据行时，就称之为覆盖索引。

覆盖索引具有以下特点和优点：
1. **减少磁盘IO：** 因为覆盖索引包含了查询所需的数据列，数据库系统可以直接从索引中获取数据，而无需访问数据表，从而减少了磁盘IO操作。这通常会显著提高查询性能，尤其是在大型数据表上。
2. **减少内存占用：** 由于覆盖索引通常比完整数据行小，所以可以减少内存使用。这对于数据库缓存的性能有积极影响，因为更多的索引页可以驻留在内存中。
3. **加速查询速度：** 覆盖索引可以加速查询速度，因为不需要额外的数据检索操作。这对于频繁执行的查询特别有用，如报表查询和分析查询。
4. **降低锁定的持续时间：** 当查询使用覆盖索引时，需要锁定的数据行较少，因此可以减少锁定的持续时间，提高并发性。
5. **减少网络开销：** 对于分布式数据库系统，使用覆盖索引可以减少数据传输的网络开销，因为不需要传输完整的数据行，只需要索引和查询的列。
## 什么是索引下推
索引下推的优点包括：
- 减少了数据检索的工作量，降低了IO操作的成本。
- 减少了网络传输的数据量，尤其在分布式数据库中有用。
- 改善了查询性能，特别是对于大型数据表和复杂查询。
- 减少了不必要的回表操作。对于查找出来的数据，先过滤掉不符合条件的，其余的再去主键索引树上查找

在不使用索引下推的情况下，在使用非主键索引进行查询时，存储引擎通过索引检索到数据，然后返回给 MySQL 服务器，服务器判断数据是否符合条件。
而有了索引下推之后，如果存在某些被索引列的判断条件时，MySQL 服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合 MySQL 服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给 MySQL 服务器。
索引条件下推优化可以**减少存储引擎查询基础表的次数**，也可以减少 MySQL 服务器从存储引擎接收数据的次数。
## 存储引擎
### 有哪些常见的存储引擎
1. **InnoDB**: InnoDB是MySQL的默认存储引擎。它支持事务处理，具有ACID（原子性、一致性、隔离性和持久性）属性，并且提供了行级锁定，适用于大多数应用。
2. **MyISAM**: MyISAM是另一种常见的存储引擎，它适用于读密集型应用。它不支持事务和行级锁定，但具有较快的读取性能。
3. **Memory**: Memory存储引擎将数据存储在内存中，适用于需要快速访问的临时数据。但是，如果MySQL重启或崩溃，数据将会丢失。
4. **CSV**: CSV存储引擎将数据以逗号分隔的格式存储在文本文件中，适合导入和导出数据。
5. **Archive**: Archive存储引擎用于存储大量历史数据，它具有较高的压缩比率，但不支持索引。
6. **Blackhole**: Blackhole存储引擎实际上不存储数据，它将所有写入的数据丢弃，用于复制和日志记录场景。
7. **Federated**: Federated存储引擎允许从一个MySQL服务器访问另一个MySQL服务器上的表，用于分布式数据库场景。
8. **NDB Cluster**: NDB Cluster存储引擎是MySQL Cluster的一部分，支持高可用性和分布式数据库，适用于大规模应用。
### MylSAM和 InnoDB的区别?
1. **事务支持：**
    - **MyISAM：** MyISAM不支持事务。这意味着它不适用于需要事务支持的应用，如银行应用或在线购物网站。
    - **InnoDB：** InnoDB支持事务。它提供了ACID（原子性、一致性、隔离性和持久性）属性，可以确保数据的完整性和一致性。
2. **锁定级别：**
    - **MyISAM：** MyISAM使用表级锁定（Table-level Locking），这意味着在执行写操作时，整个表将被锁定，阻塞其他写操作。
    - **InnoDB：** InnoDB使用行级锁定（Row-level Locking），这使得多个事务可以同时操作同一表的不同行，提高了并发性能。
3. **外键支持：**
    - **MyISAM：** MyISAM不支持外键约束。它不会强制执行引用完整性，因此需要应用程序自行管理外键关系。
    - **InnoDB：** InnoDB支持外键约束。它可以在数据库层面强制执行引用完整性，确保数据的一致性。
![[Pasted image 20231004140518.png]]
### InnoDB的四大特性?
1. **插入缓冲（Insert Buffer）：**
    - 插入缓冲是 InnoDB 存储引擎的一个特性，用于优化插入操作的性能。
    - 当执行插入操作时，数据首先被写入到插入缓冲中，然后根据适当的时机（通常是在后台任务执行时）将数据合并到主要数据页中。
    - 这减少了插入操作引起的磁盘 I/O 操作，提高了插入性能。
2. **二次写（Double Write）：**
    - 二次写是一项用于提高数据完整性的安全措施。
    - 当数据写入磁盘时，InnoDB 将数据首先写入到一个称为 doublewrite buffer 的地方，然后再写入到实际的数据文件。
    - 如果在写入过程中发生崩溃，InnoDB 可以从 doublewrite buffer 中恢复数据，以避免数据损坏或丢失。
3. **自适应哈希索引（Adaptive Hash Index，AHI）：**
    - 自适应哈希索引是 InnoDB 存储引擎中的一种优化技术，用于加速哈希索引的访问。
    - 在某些情况下，InnoDB 使用哈希索引来提高查询性能。AHI 动态地调整哈希索引的大小和位置，以适应查询模式和工作负载的变化。
    - AHI 的目标是确保在高负载环境下，哈希索引仍然可以有效提高查询性能。
4. **预读（Read Ahead）：**
    - 预读是 InnoDB 存储引擎的一项优化技术，用于减少磁盘 I/O 操作的开销。
    - 当执行查询时，InnoDB 可以预读邻近的数据页，因为查询通常不仅仅涉及单个数据页。这样，在查询需要这些数据页时，它们已经在内存中，减少了磁盘访问的需求，提高了查询性能。
### InnoDB为何推荐使用自增主键
总之就是有序
1. **性能优化：** 自增主键通常是一个递增的整数，由数据库自动生成和维护。这样的主键在插入新记录时非常高效，因为数据库无需进行复杂的主键冲突检查和排序操作。这可以显著提高插入性能，特别是在高并发的情况下。
2. **减少索引碎片：** 自增主键有序且递增，这导致了索引的局部性。这有助于减少索引碎片，使索引树更紧凑，提高了索引查询性能。相比之下，如果使用随机或非递增的主键，索引树可能会变得更加分散，导致性能下降。
3. **提高缓存效率：** 自增主键的有序性还有助于提高数据库缓存的效率。数据库系统通常使用缓冲池来存储常用的数据页，有序的主键可以更好地利用缓存，减少了磁盘IO操作。
4. **避免主键冲突：** 自增主键的生成是由数据库管理的，因此几乎不会发生主键冲突的情况。使用自增主键可以避免需要应对插入冲突的额外处理。
5. **简化数据维护：** 自增主键可以更容易地跟踪和维护数据，因为它们是有序的。这对于数据库管理员和开发人员来说更加直观。
### 如何选择存储引擎?
- InnoDB：用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询之外，还包含很多的更新、删除操作
- MyISAM：以**读操作和插入操作**为主，只有很少的更新和删除操作
- MEMORY：将所有数据保存在内存中，访问速度快，通常用于临时表及缓存
## 存储结构
### 什么是InnoDB的页、区、段
在InnoDB存储引擎中，数据存储被组织成多个层次结构，包括页、区（也称为块或块组），和段。以下是对这些概念的解释：
1. **页（Page）：** InnoDB的最基本的存储单元是页，通常大小为16KB。每个页可以包含一定数量的数据行。**页是最小的存储单位**
2. **区（Block或Chunk）：** 区是一个逻辑的概念，它是由多个连续的页组成的一组数据。通常，一个区包含多个相邻的页，以提高磁盘I/O性能。通常大小为1MB（64页）
3. **段（Segment）：** 段是一个更大的逻辑单元，由多个区组成。每个段包含一个或多个InnoDB表的数据和索引
![[Pasted image 20231004141351.png]]
### 页由哪些数据组成?
![[Pasted image 20231004165805.png]]
1. **页头（Page Header）：** 页头包含了一些元数据信息，如页号、页类型、以及存储在页中数据的字节数等。页头还包括一个指向下一个页的指针，这使得InnoDB可以组织多个页成为一个链表。 
2. **系统信息（System Information）：** 页的系统信息包括一些控制和管理数据，例如数据页的版本号、回滚段信息等。
3. **数据行（Data Rows）：** 数据页中包含了表的数据行。每行数据都被存储在数据页中，这些数据行按照表的主键顺序排列。数据行中存储了表的列数据，以及一些附加信息，如行格式、NULL标志位等。
### 页中插入记录的过程
1. **分配空间：** 当需要插入新的记录时，InnoDB首先会查找合适的空闲页或空闲空间。如果没有足够的空间，它会分配一个新的数据页或者从已有的空闲页中分配空间。
2. **构建数据行：** 在已分配的页中，InnoDB会构建新的数据行，将要插入的数据填充到行中。这个过程包括将每个列的数据逐一写入行中，并处理NULL值等情况。
3. **插入到页中：** 构建好的数据行将被插入到已分配的页中，通常是按照主键的顺序插入。如果主键是自增的，新的数据行将被插入到合适的位置，以维持主键的有序性。
4. **更新页的元数据：** 插入数据后，InnoDB会更新页的元数据，包括页头中的记录数和其他信息。同时，它还会更新索引数据，以便在查询时能够快速访问新插入的记录。
5. **提交事务：** 如果插入操作是在一个事务中进行的，需要在事务提交时才会将数据写入磁盘。这确保了数据的持久性。
6. 1）如果 Free Space 的空间足够的话，直接分配空间来添加纪录，并将插入前最后一条纪录的 next_record 指向当前插入的纪录，将当前插入纪录的 next_record 指向 supremum 纪录。
2）如果 Free Space的 空间不够的话，则首先将之前删除造成的碎片重新整理之后，按照上述步骤插入纪录。
3）如果当前页空间整理碎片之后仍然不足的话，则重新申请一个页，将页初始化之后，按照上述步骤插入纪录
### 什么是buffer pool
Buffer Pool 有一项特技叫预读，存储引擎的接口在被 Server 层调用时，会在响应的同时进行预判，将下次可能用到的数据和索引加载到 Buffer Pool。
预读策略有两种，为线性预读（linear read-ahead）和随机预读（random read-ahead），其中 InnoDB 默认使用线性预读，随机预读已经基本废弃。
线性预读认为如果前面的请求顺序访问当前区（extent）的页，那么接下来的若干请求也会顺序访问下一个区的页，并将下一个区加载到 Buffer Pool。

要优化预读失效（提前把页放入了缓冲池，但最终 MySQL 并没有从页中读取数据），则让预读失败的页停留在缓冲池里的时间尽可能短，预读成功的页停留时间尽可能长。具体将 LRU 链分代实现，即**新生代和老年代**（old subList），预读的页加入缓冲池时只加入到老年代头部，只有真正被预读成功，则再加入新生代。当批量扫描大量数据时，可能导致把缓冲池的所有页都替换出去，导致大量热数据被换出，MySQL 性能急剧下降。InnoDB 缓冲池加入了一个**老生代停留时间窗口**的机制，只有满足预读成功并且在老生代停留时间大于该窗口才会被放入新生代头部。
### 什么是Change Buffer
Change Buffer（变更缓冲区）是InnoDB存储引擎的一个重要组件，它用于优化磁盘上的数据更新操作。
为了减少磁盘IO，InnoDB在Buffer Pool中开辟了一块内存，用来存储变更记录，为了防止异常宕机丢失缓存，当事务提交时会将变更记录持久化到磁盘。Change Buffer的主要目标是减少随机磁盘写入，提高数据库的写入性能。它的工作原理如下：
1. **延迟磁盘写入：** 当有更新、插入或删除操作时，InnoDB不会立即将这些操作直接写入磁盘上受影响的数据页。相反，它将这些变更记录到Change Buffer中，同时更新内存中的数据页。
2. **合并操作：** 在后续查询中，InnoDB会检查Change Buffer中的变更，将其应用到相应的数据页。这样可以实现一种延迟写入的机制，将多个随机磁盘写入操作合并为更少的顺序写入操作。这减少了随机I/O操作，提高了写入性能。
3. **减轻随机写入：** 随机写入通常比顺序写入更为昂贵，因为磁盘需要寻找不同的位置进行写入。Change Buffer的使用有助于减轻随机写入，从而提高了数据库的写入性能。
4. **适用于非聚簇索引：** Change Buffer主要用于非聚簇索引（如辅助索引），因为聚簇索引（主键索引）的数据页通常都在内存中，直接更新数据页即可。
## InnoDB
### InnoDB 架构设计？
以下主要从内存和线程的角度分析 InnoDB 的架构。
![[Pasted image 20231004172019.png]]
内存中的数据区域划分：
![[Pasted image 20231004172030.png]]
### InnoDB 有哪些线程？
线程的作用：
1）负责刷新内存池中的数据，保证缓冲池的内存缓冲的是最近的数据
2）已修改的数据文件刷新到磁盘文件
3）保证数据库发生异常的情况下InnoDB能恢复到正常状态。
线程分类：
1）Master Thread
负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新，合并插入缓冲（INSERT BUFFER），UNDO页的回收等。
2）IO Thread
负责 AIO 请求的回调处理。
3）Purge Thread
事务提交后，undo log 可能不再需要，由 Purge Thread 负责回收并重新分配的这些已经使用的 undo 页。
4）Page Cleaner Thread
将Master Threader中刷新脏页的工作移至该线程，如上面说的FLUSH LRU LIST Checkpoint以及Async/Sync Flush Checkpoint。
### 什么是 doublewrite？
MySQL的Doublewrite机制是一种用于保证数据一致性和可靠性的机制。在MySQL中，当执行写操作时，会先将数据写入到内存中的缓冲池（Buffer Pool）中，然后再异步地将数据写入到磁盘中的数据文件中。这种异步写入的方式虽然可以提高写入性能，但也会带来一些风险，例如在写入过程中出现宕机等异常情况，可能会导致数据丢失或者数据不一致。  
  
为了解决这个问题，MySQL引入了Doublewrite机制。Doublewrite机制的基本思路是，**在将数据写入到磁盘中的数据文件之前，先将数据写入到一个专门的Doublewrite Buffer中**。这个Doublewrite Buffer是一个内存中的缓冲区，它的大小通常是一个数据页的大小。当数据写入到Doublewrite Buffer中后，MySQL会将Doublewrite Buffer中的数据同步地写入到磁盘中的一个特殊文件中，这个特殊文件通常是一个磁盘上的随机文件。  
通过这种方式，MySQL可以保证在写入数据到磁盘中的数据文件之前，先将数据写入到Doublewrite Buffer中，并将Doublewrite Buffer中的数据同步地写入到磁盘中的特殊文件中。这样，即使在写入数据到磁盘中的数据文件的过程中出现宕机等异常情况，也可以通过读取Doublewrite Buffer中的数据或者特殊文件中的数据来恢复数据的一致性和可靠性。  

### 什么是自适应哈希？
InnoDB 会监控对表上各索引页的查询执行情况，如发现建立哈希索引可以提升速度，则建立哈希索引，这是过程不需要用户干预。（默认开启）

# 事务
## 什么是数据库的事务?
数据库的事务（Transaction）是一组SQL操作的执行单元，它被视为一个不可分割的工作单元，要么全部成功执行，要么全部失败回滚，保证了数据库的一致性和数据完整性。事务是数据库管理系统（DBMS）中的核心概念，用于管理并发访问和数据一致性。
## 什么是事务的四大特性(ACID)
1. **原子性（Atomicity）：** 事务是原子的，意味着它要么全部成功执行，要么完全失败回滚。如果在事务执行期间发生错误，所有的更改将被撤销，数据库状态会回到事务开始之前的状态。
2. **一致性（Consistency）：** 事务在执行前后必须保持数据库的一致性。这意味着事务应该满足数据库的约束和规则，不会破坏数据的完整性。
3. **隔离性（Isolation）：** 多个事务并发执行时，它们应该彼此隔离，不应该互相干扰。隔离性确保了并发事务的结果与它们依次执行时的结果一致。
4. **持久性（Durability）：** 一旦事务成功提交，其结果应该永久保存在数据库中，即使发生系统崩溃或重新启动也不应丢失。持久性确保了数据的持久存储。
## 事务的并发问题（脏读、幻读和不可重复读）
1. **脏读（Dirty Read）：** 脏读发生在一个事务读取了另一个事务未提交的数据。如果第一个事务读取了未提交的数据，然后第二个事务回滚，那么第一个事务读取的数据将是无效的。这会导致不一致的数据。
2. **不可重复读（Non-repeatable Read）：** 不可重复读发生在一个事务在同一数据项上多次读取，但在这些读取之间另一个事务修改了该数据项。这导致了不同时间点的同一查询结果不一致，因为事务读取的数据在这段时间内发生了变化。
3. **幻读（Phantom Read）**：发生在一个事务在同一范围内多次查询，而在这些查询之间另一个事务插入了新的数据，导致第一个事务看到了之前不存在的数据。
4. **丢失更新（Lost Update）：** 丢失更新问题发生在两个事务同时尝试修改同一数据项，但只有一个事务的修改被保存，另一个事务的修改被覆盖或丢失。这可能导致数据的不一致性。
## 事务的隔离级别有哪些?
为了解决这些并发问题，数据库管理系统（DBMS）提供了事务隔离级别，通常有四个级别：**读未提交**（Read Uncommitted）、**读已提交**（Read Committed）、**可重复读**（Repeatable Read）和**串行化**（Serializable）。不同的隔离级别提供不同程度的隔离，以满足不同应用场景的需求。
- 在读未提交隔离级别下，最低的隔离级别，所有并发事务都可以看到彼此的未提交数据，因此容易发生脏读、不可重复读和幻读。
- 在读已提交隔离级别下，事务只能看到已提交的数据，解决了脏读问题，但仍然可能出现不可重复读和幻读。
- 在可重复读隔离级别下，事务在同一范围内的查询结果保持一致，解决了不可重复读和脏读问题，但仍然可能出现幻读。
- 在串行化隔离级别下，最高的隔离级别，事务之间完全隔离，解决了所有并发问题，但可能导致性能下降。
## ACID特性是如何实现的?
1. **原子性（Atomicity）：** 实现原子性的机制包括**事务日志和事务管理**。当事务开始执行时，DBMS会记录当前数据库的状态，以便在失败时进行回滚。如果事务的所有操作都成功，那么DBMS会提交事务，否则它会回滚事务并将数据库恢复到之前的状态。
2. **一致性（Consistency）：** DBMS通过应用事务时进行**数据验证和约束检查**来实现一致性。如果事务违反了任何约束或规则，它将被拒绝执行，从而保持数据库的一致性。
3. **隔离性（Isolation）：** DBMS通过**锁和并发控制机制**来实现隔离性。事务之间的读写操作必须遵守一定的顺序和规则，以确保它们不会相互冲突或导致不一致的结果。
4. **持久性（Durability）：** DBMS使用**事务日志**来实现持久性。在事务提交时，DBMS会将事务操作记录到事务日志中，然后逐步将这些操作写入磁盘。即使系统崩溃，DBMS可以通过重放事务日志来还原事务，确保数据的持久性。
# 锁
## 数据库锁的作用以及有哪些锁
数据库锁是用于管理并发访问数据库的机制，其主要作用是控制多个事务对共享资源（如数据表、数据行）的访问，以确保数据的一致性和完整性。锁可以防止多个事务同时对同一资源进行不同的操作，从而避免并发问题。
**从锁的粒度划分**
1. **行级锁（Row-level Lock）：** 行级锁是一种细粒度的锁，允许事务锁定表中的某一行或某几行，而不是整个表。这种锁的作用是减小锁的粒度，允许并发性更高，减少锁冲突。
2. **表级锁（Table-level Lock）：** 表级锁是锁定整个表的锁，它的粒度比行级锁更粗，通常会阻塞其他事务的操作，因此在高并发情况下可能导致性能问题。表级锁的使用应该尽量避免，除非确实需要锁定整个表。
3. **页级锁**：是粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折中的页级，一次锁定相邻的一组记录。
**从使用性质划分**：
1. **共享锁（Shared Lock）：** 也称为读锁。多个事务可以同时持有共享锁，并且不会阻塞其他事务的共享锁。共享锁用于读取操作，允许多个事务同时读取相同的资源，但阻止其他事务持有排他锁。
2. **排他锁（Exclusive Lock）：** 也称为写锁。只有一个事务可以持有排他锁，其他事务无法同时持有共享锁或排他锁。排他锁用于写入操作，确保只有一个事务可以修改资源，防止其他事务读取或写入相同的资源。
3.  **意向锁（Intention Lock）：** 意向锁是用来表示事务打算对资源进行哪种类型的锁定（共享锁或排他锁）。意向锁不会阻止其他事务获取共享或排他锁，但它们提供了一种机制，让事务了解其他事务的锁定意图，以便更好地管理锁。
**从主观上划分：**
**乐观锁**（Optimistic Lock）：顾名思义，从主观上认定资源是不会被修改的，所以不加锁读取数据，仅当更新时用版本号机制等确认资源是否被修改。乐观锁适用于多读的应用类型，可以系统提高吞吐量。
**悲观锁**（Pessimistic Lock）：正如其名，具有强烈的独占和排它特性，每次读取数据时都会认为会被其它事务修改，所以每次操作都需要加上锁。

## 隔离级别和锁的关系
1. **读未提交（Read Uncommitted）：** 这是最低的隔离级别，事务可以读取其他事务尚未提交的数据，而不会等待锁定。这意味着在此隔离级别下，可能会发生脏读（Dirty Read），因为事务可以读取到其他事务未提交的数据，即使这些数据最终可能被回滚。
2. **读已提交（Read Committed）：** 在这个隔离级别下，事务只能读取已提交的数据，避免了脏读。但是，它允许了不可重复读和幻读。为了实现这个隔离级别，数据库通常会使用短暂**共享锁**（S锁）来保护读操作，确保其他事务不能修改被读取的数据。
3. **可重复读（Repeatable Read）：** 这个隔离级别进一步提高了隔离性，确保在同一事务内多次读取相同数据时不会发生不可重复读。为了实现这个隔离级别，数据库通常使用**行级锁**（Row-level Locks）或快照读取（Snapshot Isolation）来保护数据，确保事务在读取期间不会被其他事务修改。
4. **串行化（Serializable）：** 这是最高的隔离级别，事务被完全隔离，避免了所有并发问题，包括脏读、不可重复读和幻读。为了实现这个隔离级别，数据库通常会使用**排他锁**（X锁）来锁定被事务读取或修改的数据，确保其他事务无法同时访问。
## InnoDB中的锁算法
- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
- Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身
1. **行级锁（Row-level Locks）：** InnoDB支持行级锁，这意味着事务可以针对数据表中的特定行或范围进行锁定，而不是整个表。这提高了并发性，允许多个事务同时访问不同的行。InnoDB使用B+树索引来管理行级锁。
2. **间隙锁（Gap Locks）：** 间隙锁是一种特殊的锁，用于锁定范围内的间隙（两个值之间的空间），以防止其他事务插入新行。这有助于避免幻读问题。当事务查询数据时，InnoDB可以自动获取间隙锁来保护查询范围。
3. **Next-Key Locks：** InnoDB使用Next-Key Locks来处理范围查询和避免幻读。这种锁将行级锁与间隙锁结合起来，确保不会有新行插入到查询范围内。
## 什么是快照读和当前读
1. **快照读（Snapshot Read）：** 快照读是在数据库中读取数据的一种方式，它读取的是一个事务开始时的数据快照，而不受其他正在进行的事务的影响。快照读通常用于具有较低隔离级别（如读未提交或读已提交）的事务中，或者在某些情况下用于具有更高隔离级别（如可重复读或串行化）的事务，以提高并发性和性能。
    - **快照读的特点：**
        - **不会阻塞**其他事务的写入操作，允许多个事务同时读取相同的数据。
        - 读取的是**事务开始时的数据状态**，即使其他事务在事务执行过程中修改了数据，快照读也不受影响。
        - 快照读通常**不需要显式的锁定操作**，因为它们不会与其他事务发生冲突。
2. **当前读（Current Read）：** 当前读是在数据库中读取数据的另一种方式，它读取的是最新的数据状态，考虑了其他正在进行的事务对数据的修改。当前读通常用于具有更高隔离级别（如可重复读或串行化）的事务中，以确保数据的一致性和完整性。
    - **当前读的特点：**
        - **会阻塞**其他事务的写入操作，因为它需要获取锁以确保数据的一致性。
        - 读取的是**当前时刻的数据状态**，考虑其他事务对数据的修改。如果其他事务正在修改被读取的数据，当前读可能需要等待锁释放。
        - 当前读通常**需要显式的锁定操作**，以确保数据的一致性。不同的数据库系统可能有不同的方式来实现当前读，如共享锁或排他锁。
选择快照读还是当前读取决策通常取决于应用程序的需求和隔离级别。如果应用程序可以**容忍读取稍旧**的数据快照，并且需要**更高的并发性**，那么**快照读**可能是一个更好的选择。如果**数据的一致性**对应用程序至关重要，那么**当前读**可能更适合，但可能会导致一些性能损失，因为它需要等待锁的释放。
## 什么是 MVCC以及实现
MVCC（Multi-Version Concurrency Control）是一种用于实现数据库事务的并发控制机制。它允许多个事务同时访问数据库，而不会发生数据一致性问题，同时提供了高度的并发性。
MVCC的核心思想是在**数据库中维护多个版本的数据**，每个事务在读取数据时，可以看到某个时间点的数据版本，而不会被其他事务的修改所干扰。这使得事务可以并发地读取和修改数据，而不需要加锁等待其他事务的释放。

MVCC的实现通常包括以下关键组件：
1. **版本号或时间戳：** 每个数据行都会关联一个版本号或时间戳，表示该数据行的创建或修改时间。不同的数据库管理系统使用不同的方式来表示版本号或时间戳。
2. **Read View（读视图）：** 每个事务都有自己的读视图，它包含了事务开始时的时间戳或版本号。事务只能看到在其读视图之前或等于其时间戳的数据版本。
3. **Write View（写视图）：** 当事务修改数据时，它会在写视图中创建新的数据版本，并将事务的时间戳或版本号与该版本关联。这允许其他事务继续访问旧版本的数据，而不会受到新版本的影响。
4. **垃圾收集：** 数据库定期清理过时的数据版本，以释放存储空间。垃圾收集的策略可以根据数据库系统的实现不同而异。
MVCC的实现使得**读操作不会阻塞写操作，写操作也不会阻塞读操作**，因此提高了数据库的并发性能。
MVCC是支持高并发事务处理的关键技术之一，有助于提供高性能和数据一致性。
# 进阶功能
## 视图
## 存储过程
### 什么是存储过程?
1. 存储过程是一组 SQL 语句的集合，它们一起执行特定的任务或操作。
2. 存储过程可以包含输入参数、输出参数和返回值。
3. 存储过程可以执行数据操作（插入、更新、删除等）和数据检索。
4. 存储过程通常不返回单个值，而是可以执行多个 SQL 语句并进行一系列操作。
5. 存储过程可以独立执行，也可以被其他 SQL 语句或应用程序调用。
### 存储过程和函数的区别
1. 函数是一段封装了特定逻辑的可重复使用代码块，它接收输入参数并返回一个单一的值。
2. 函数必须有一个返回值，通常用于计算和返回单个标量值，例如求和、平均值等。
3. 函数不能执行数据操作（插入、更新、删除等），只能用于数据检索和计算。
4. 函数的调用通常包含在 SQL 查询中，以获取或计算值。
主要区别：
1. **返回值类型：** 存储过程通常没有返回值，而函数必须返回一个值。
2. **用途：** 存储过程用于执行一系列数据库操作，而函数用于计算和返回单一的值。
3. **参数传递：** 存储过程可以包含输入参数、输出参数和返回值，而函数只有输入参数和返回值。
4. **调用方式：** 存储过程可以独立执行，也可以由其他 SQL 语句或应用程序调用，而函数通常是在 SQL 查询中调用的。
5. **数据操作：** 存储过程可以执行数据操作，如插入、更新、删除，而函数只能用于数据检索和计算。
## 触发器
# 集群
### MySQL中有哪些常见日志
1. **Redo日志（Redo Log）：** Redo日志是InnoDB存储引擎的一个关键组成部分。它记录了每个事务所做的修改操作，以便在数据库崩溃或异常关闭时进行恢复。Redo日志的作用是确保事务的持久性（Durability）特性，即使在数据库崩溃时，也可以通过重放Redo日志来还原未提交的事务。这是数据库的事务安全性的核心保证。
2. **Undo日志（Undo Log）：** Undo日志也是InnoDB存储引擎的一部分，它用于支持事务的隔离级别和回滚操作。Undo日志记录了事务执行前的数据版本，以便在事务回滚时将数据还原到原始状态。此外，Undo日志还用于提供多版本并发控制（MVCC），允许多个事务并发地访问相同的数据行而不会相互干扰。
3. **二进制日志（Binary Log）：** 二进制日志记录了数据库中的所有更改操作，包括INSERT、UPDATE和DELETE等。它不仅用于数据恢复，还用于数据库复制和主从同步。通过将二进制日志从主数据库传输到一个或多个从数据库，可以实现数据复制、故障恢复和负载均衡等功能。二进制日志也可用于审计和安全性监控。

其它相关的日志（了解）
1. **错误日志（Error Log）：** 错误日志记录了MySQL服务器的错误消息、警告以及其他运行时错误信息。这对于诊断数据库问题非常重要，例如配置错误、崩溃和异常终止。
2. **查询日志（Query Log）：** 查询日志记录了每个进入MySQL服务器的查询语句，包括SELECT、INSERT、UPDATE和DELETE等。它可以用于分析数据库的查询性能和追踪潜在的性能问题。请注意，查询日志在生产环境中可能会产生大量的数据，因此需要谨慎使用。
3. **慢查询日志（Slow Query Log）：** 慢查询日志记录了执行时间超过一定阈值（通常是指定的时间值）的查询语句。这有助于识别性能较差的查询，以便进行优化。慢查询日志的启用和配置允许数据库管理员监视和改进查询性能。
4. **中继日志（relay log）**：在从节点中存储接收到的 binlog 日志内容，用于主从同步。
## 主从复制
### 什么是主从复制
主从复制（Master-Slave Replication）是一种数据库复制技术，用于将一个数据库服务器（主服务器）上的数据复制到一个或多个其他数据库服务器（从服务器）。主从复制通常用于提高数据库的可用性、负载均衡、数据备份和故障恢复。
### 主从复制的作用
- **读写分离：** 主服务器负责写入操作，而从服务器用于读取操作，以分担主服务器的负载，提高性能。
- **数据备份：** 从服务器可以用于备份数据，而不影响主服务器的性能。备份可以用于灾难恢复和数据恢复。
- **高可用性：** 如果主服务器发生故障，可以将一个从服务器升级为新的主服务器，从而实现快速故障恢复。
- **分布式数据：** 主从复制可以用于在不同地理位置或数据中心之间复制数据，以实现分布式数据的复制和访问。
### 主从复制的架构
**一主一从或一主多从**
在主库的请求压力非常大时，可通过配置一主多从复制架构实现读写分离，把大量对实时性要求不是很高的请求通过负载均衡分发到多个从库上去读取数据，降低主库的读取压力。而且在主库出现宕机时，可将一个从库切换为主库继续提供服务。
**主主复制**
双主复制架构适用于需要进行主从切换的场景。 两个数据库互为主从，当主库宕机恢复后，由于它还是原来从库（现在主库）的从机，所以它还是会复制新的主库上的数据。那么无论主库的角色怎么切换，原来的主库都不会脱离复制环境。
**多主一从（5.7 开始支持）**
**联级复制**

1. **主服务器（Master）：** 主服务器是数据源，它包含了要复制的数据库。所有的写入操作都在主服务器上执行。主服务器将写入操作的日志记录到二进制日志（Binary Log）中。
2. **从服务器（Slave）：** 从服务器是主服务器的副本，它从主服务器复制数据。从服务器接收主服务器的二进制日志，并将其应用到本地数据库中，以保持数据与主服务器同步。
3. **复制通道（Replication Channel）：** 复制通道是主从复制的通信通道，它用于传输主服务器上的二进制日志到从服务器，并确保数据的一致性。通常，主从服务器之间的通信是基于TCP/IP的。
4. **日志文件位置和位置坐标（Log File Position and Position Coordinates）：** 主服务器会记录每个二进制日志文件的位置和位置坐标，从服务器会跟踪这些信息，以确保从正确的位置开始复制数据。
5. **同步方式（Synchronization Method）：** 从服务器可以使用异步或半同步方式与主服务器同步数据。在异步模式下，从服务器会根据自己的速度来复制数据，而主服务器不会等待从服务器确认收到数据。在半同步模式下，主服务器会等待至少一个从服务器确认收到数据后才继续写入，以确保更高的数据一致性。
### 主从复制的实现原理（工作过程）
（1）Master节点将数据的改变记录成二进制日志（bin log），当Master上的数据发生改变时，则将其改变写入二进制日志中。
（2）Slave节点会在一定时间间隔内对Master的二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/O线程请求 Master的二进制事件。
（3）同时Master节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至Slave节点本地的中继日志（Relay log）中，Slave节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，即解析成 sql 语句逐一执行，使得其数据和 Master节点的保持一致，最后I/O线程和SQL线程将进入睡眠状态，等待下一次被唤醒。
![[Pasted image 20231004145235.png]]
### 什么是异步复制和半同步
1. **异步复制（Asynchronous Replication）：**
    - 在异步复制模式下，主服务器执行写入操作后不会等待从服务器的确认，而是立即继续处理其他操作。
    - 从服务器在接收到主服务器的数据变更后，会尽力快速地复制和应用这些变更，但主服务器不会等待从服务器的完成确认。
    - 异步复制具有高吞吐量，因为主服务器不会因为等待从服务器的确认而受到性能限制。
    - 缺点是，如果从服务器出现故障或延迟，可能会导致数据在主从之间的不一致。主服务器无法保证所有写入都已成功应用到从服务器。
2. **半同步复制（Semi-Synchronous Replication）：**
    - 在半同步复制模式下，主服务器在执行写入操作后会等待至少一个从服务器确认收到并应用了这些数据变更，然后才继续处理其他操作。
    - 这意味着在半同步复制中，主服务器确保写入的数据至少被一个从服务器接收和应用，从而提高了数据的一致性。
    - 半同步复制在主从之间引入了一定程度的延迟，因为主服务器需要等待从服务器的响应。但与完全同步复制相比，延迟通常较小，且性能较好。

选择异步复制还是半同步复制通常取决于应用程序的需求和可用性要求：
- 异步复制通常用于需要高吞吐量和性能的场景，而对数据一致性要求相对较低的情况。它适用于读写分离和负载均衡。
- 半同步复制通常用于需要更高数据一致性和可用性的场景，即使需要一些延迟。它可以提供较好的数据保护，适用于关键业务和故障恢复。
### 主从中常见问题以及解决?（了解）
在主从复制（Master-Slave Replication）架构中，可能会出现一些常见问题，这些问题可能会影响数据一致性、性能和可用性。以下是一些常见的问题以及解决方法：
1. **复制延迟（Replication Lag）：**
    - **问题描述：** 从服务器的数据复制与主服务器之间存在延迟，导致从服务器上的数据不及时与主服务器同步。
    - **解决方法：**
        - 优化网络连接：确保主从服务器之间的网络连接稳定和高速。
        - 调整复制线程参数：可以尝试调整从服务器上的复制线程参数，如增加线程数量、提高读取速度等。
        - 升级硬件：提升从服务器的硬件性能，以提高数据处理速度。
        - 考虑半同步复制：使用半同步复制可以减小延迟，因为主服务器会等待至少一个从服务器确认收到数据。
2. **数据不一致（Data Inconsistency）：**
    - **问题描述：** 从服务器上的数据与主服务器不一致，可能由于数据损坏、复制中断或其他问题引起。
    - **解决方法：**
        - 定期校验数据：定期运行数据一致性检查，例如校验表行数、数据内容等，以便及时发现问题并修复。
        - 数据恢复：如果发现数据不一致，可以使用主服务器的备份或重新初始化从服务器来修复数据。
3. **主服务器故障（Master Server Failure）：**
    - **问题描述：** 主服务器发生故障，导致主从复制中断。
    - **解决方法：**
        - 自动故障转移：配置自动故障转移机制，当主服务器故障时，自动将一个从服务器提升为新的主服务器。
        - 手动切换：在主服务器故障时，手动切换到备用主服务器，以确保数据库的可用性。
4. **复制错误和冲突（Replication Errors and Conflicts）：**
    - **问题描述：** 复制过程中可能会出现错误，如主从服务器上的数据冲突，导致复制失败。
    - **解决方法：**
        - 监控复制错误：定期监控复制过程中的错误和警告，并记录它们以进行分析。
        - 处理冲突：在数据冲突发生时，手动解决冲突，确保数据一致性。

# SQL
## 语法
### 常见的聚合查询(函数)
1. **COUNT()：** 用于计算符合条件的行数。可以用于统计某个列的非空值数量，也可以用于统计整个表中的行数。
```
SELECT COUNT(*) FROM tablename; -- 统计表中的总行数 
SELECT COUNT(columnname) FROM tablename WHERE condition; -- 统计符合条件的行数
```
2.  **SUM()：** 用于计算某个列的数值总和。
   `SELECT SUM(columnname) FROM tablename WHERE condition; -- 计算符合条件的列的总和`
3. **AVG()：** 用于计算某个列的平均值。
    `SELECT AVG(columnname) FROM tablename WHERE condition; -- 计算符合条件的列的平均值`
4. **MAX()：** 用于找出某个列的最大值。
    `SELECT MAX(columnname) FROM tablename WHERE condition; -- 找出符合条件的列中的最大值`
5. **MIN()：** 用于找出某个列的最小值。
    `SELECT MIN(columnname) FROM tablename WHERE condition; -- 找出符合条件的列中的最小值`
6. **GROUP BY：** 用于按照一个或多个列的值对数据进行分组，并在每个分组上执行聚合函数。
  ```
 SELECT column1, SUM(column2) FROM tablename GROUP BY column1; 
 -- 按 column1 列的值分组，并计算每个分组的 column2 列的总和
  ```
7. **HAVING：** 用于筛选分组后的结果集，类似于WHERE，但在GROUP BY之后使用。
    `SELECT column1, SUM(column2) FROM tablename GROUP BY column1 HAVING SUM(column2) > 100; 
    `-- 筛选总和大于 100 的分组`
8. **DISTINCT：** 用于返回唯一的值，通常与聚合函数一起使用。
    `SELECT DISTINCT columnname FROM tablename; -- 返回指定列的唯一值`
### 几种关联查询?
1. **INNER JOIN：** INNER JOIN 返回两个或多个表中满足连接条件的行。它只返回匹配的行，如果没有匹配的行，则不返回任何数据。
    `SELECT orders.order_id, customers.customer_name FROM orders INNER JOIN customers ON orders.customer_id = customers.customer_id;`
2. **LEFT JOIN（或LEFT OUTER JOIN）：** LEFT JOIN 返回左边表中的所有行，以及右边表中满足连接条件的匹配行。如果右边表中没有匹配的行，将返回 NULL 值。
    `SELECT customers.customer_name, orders.order_id FROM customers LEFT JOIN orders ON customers.customer_id = orders.customer_id;`
3. **RIGHT JOIN（或RIGHT OUTER JOIN）：** RIGHT JOIN 与 LEFT JOIN 相反，它返回右边表中的所有行
    `SELECT customers.customer_name, orders.order_id FROM customers RIGHT JOIN orders ON customers.customer_id = orders.customer_id;`
4. **FULL JOIN（或FULL OUTER JOIN）：** FULL JOIN 返回左边表和右边表中的所有行，如果没有匹配的行，则返回 NULL 值。
    `SELECT customers.customer_name, orders.order_id FROM customers FULL JOIN orders ON customers.customer_id = orders.customer_id;`
5. **SELF JOIN：** SELF JOIN 是一种特殊类型的关联查询，用于连接同一表中的不同行。
    `SELECT e1.employee_name, e2.employee_name AS manager_name FROM employees e1 LEFT JOIN employees e2 ON e1.manager_id = e2.employee_id;`
### Where和 Having的区别
1. 执行时机不同: where是分组之前进行过滤，不满足where条件，不参与分组;而having是分组之后对结果进行过滤。
2. 判断条件不同:where不能对聚合函数进行判断，而having可以。
### SQL关键字的执行顺序
`SELECT` > `FROM` > `WHERE` > `GROUP BY` > `HAVING` > `ORDER BY` > `LIMIT / OFFSET`
![[Pasted image 20230726161617.png]]
![[Pasted image 20231004171325.png]]
### In和 Exists的区别?
- `IN` 用于比较值，而 `EXISTS` 用于比较是否存在符合条件的记录。
- `IN` 子查询返回一列的值列表，而 `EXISTS` 子查询通常返回一个布尔值。
- 通常情况下，`EXISTS` 在子查询的结果集很大或需要检查是否存在时更高效，而 `IN` 用于比较值列表。
### Union和Union All的区别
- `UNION` 去除结果集中的重复行，返回唯一的行。如果两个查询中有相同的行，`UNION` 会只返回一次。同时进行默认规则的排序
- `UNION ALL` 保留结果集中的重复行，返回所有行，包括重复的行。
### Drop、Delete和 Truncate的区别
- `DROP` 用于删除整个数据库对象。（表对象）
- `DELETE` 用于删除表中符合条件的行。（表行及其数据）
- `TRUNCATE` 用于删除表中的所有数据，但保留表结构。（表数据）
- 从执行速度上讲：`drop > truncate >> DELETE`。
## 优化
### 一条SQL是如何执行的
![[Pasted image 20231004171523.png]]
1. **语法解析和分析：** 当您发送一条 SQL 查询时，DBMS 首先会进行语法解析和分析，以确保查询语句的语法正确性。如果语法不正确，将生成错误消息并报告给用户。
2. **查询优化：** 一旦语法正确，DBMS 会进行查询优化。这个步骤的目标是找到执行查询的最有效方法。优化器会考虑哪些索引可用，哪个表应该先扫描等等，以尽量减少查询的执行时间。
3. **查询执行计划生成：** 基于优化的结果，DBMS 生成一个查询执行计划。这个计划描述了如何获取和组合数据以满足查询的要求。这可能包括表扫描、索引扫描、连接操作等。
4. **数据检索和操作：** 根据查询执行计划，DBMS 开始执行实际的数据检索和操作。这可能包括从磁盘读取数据、应用过滤条件、执行连接、排序和聚合等操作。
5. **结果返回：** 一旦数据操作完成，DBMS 将结果返回给用户或应用程序。这可能是一组行和列，取决于查询的类型。
6. **事务处理：** 如果查询涉及到事务操作（如插入、更新、删除），DBMS 会确保这些操作按照 ACID（原子性、一致性、隔离性、持久性）属性进行处理，以维护数据的完整性和一致性。
7. **错误处理：** 如果在执行过程中发生了错误（例如，违反了约束条件或唯一性约束），DBMS 会生成错误消息并采取适当的操作，通常是回滚事务或报告错误给用户。
8. **资源释放：** 在查询执行完毕后，DBMS 会释放使用的系统资源，如锁、缓存等，以便其他查询可以使用这些资源。
### 如何判断SQL是否走了索引
1. **执行计划（Execution Plan）：**
    - 通过关键字 `EXPLAIN` 或 `EXPLAIN ANALYZE`。这会显示查询的执行方式，包括是否使用了索引。
    - 查询执行计划中通常会显示是否使用了索引，以及使用的是哪个索引。
2. **查看索引使用情况：**
    - 可以查看数据库的索引使用情况，以确定哪些索引被频繁使用。
    - 在 MySQL 中可以使用 `SHOW INDEX` 命令来查看索引统计信息和使用情况
    `SHOW INDEX FROM your_table;`
    这将显示表中每个索引的统计信息，包括被扫描的次数和最后扫描的时间。
3. **监控工具：**
    - 使用数据库性能监控工具可以实时监视查询的性能，并查看哪些查询使用了索引。
    - 常见的数据库监控工具包括 MySQL 的 Performance Schema、PostgreSQL 的 pg_stat_statements 等。
4. **观察执行时间：**
    - 通常情况下，使用索引的查询往往比不使用索引的查询执行更快。
    - 您可以通过比较查询的执行时间来初步判断是否走了索引。
### 索引失效的几种情况?
1. **字符串不加引号** ：字符串类型字段使用时，不加引号，会发生隐式类型转换，索引将失效
2. **索引列使用函数或表达式：** 如果在查询条件中对索引列使用了函数或表达式，索引可能会失效。因为索引通常无法直接应用于被处理的函数或表达式。
3. **使用 OR 条件：** 在查询条件中使用 OR 条件时，索引可能会失效。因为 OR 条件会导致数据库优化器难以选择最佳的索引。
4. **使用通配符开头的 LIKE：** 当使用以通配符开头的 `LIKE` 查询时，索引可能会失效。通配符在查询开始位置时，索引无法有效提高性能。
5. **小表扫描：** 如果表的大小很小，优化器可能会选择对整个表进行扫描而不是使用索引，因为扫描整个表可能更快。
6. **最左匹配原则**：联合索引不使用第一列，索引失效
7. 在索引列上使用 IS NULL 或 IS NOT NULL操作。最好给列设置默认值
8. 在索引字段上使用not，<>，!=。不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 优化方法： key<>0 改为 key>0 or key<0。

### Where子句如何优化?（了解）
1. 使用like进行模糊查询时应注意,不要在关键词前加%，避免索引失效
2. 使用 union all 来替换 or 条件，避免进行全表扫描，降低效率
3. 在where子句中使用 ！= 或 <>操作符，将不会使用索引，会进行全表查询，避免使用这种操作符
4. 避免在查询条件中对列进行函数操作，因为这可能会导致索引失效
5. 在使用索引字段作为条件时，如果该索引是联合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引（最左前缀原则），否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致
6. 如果只需要查询结果集的一部分，可以使用 `LIMIT` 子句来限制返回的行数。这可以减少数据检索和传输的成本。
7. 对于分页查询，使用合适的分页技术，例如基于游标的分页，以减少性能开销。
### 超大分页或深度分页如何处理
1. **使用游标分页：** 相对于传统的基于偏移量的分页，游标分页更适合处理深度分页。游标分页将查询结果集划分为较小的块，每次只请求一页数据。数据库系统通常提供游标分页的支持。这可以减少传输和处理大量数据的成本。
2. **利用索引：** 确保查询中涉及的列有适当的索引。索引可以帮助数据库系统快速定位到需要的数据行。优化索引设计可以减少查询的响应时间。
3. **缓存查询结果：** 如果查询结果很大，但数据不经常变化，可以考虑将查询结果缓存在应用程序或数据库中，以减少重复查询的成本。这对于静态数据或者不经常变化的数据非常有用。
4. **避免不必要的字段：** 只请求需要的字段，避免在查询中选择所有字段。这可以减少数据传输的开销。
5. **增量分页：** 使用增量分页策略，而不是一次性加载所有分页数据。例如，每次加载一定数量的页，而不是一次性加载所有数据。
6. **定期清理历史数据：** 如果查询的数据是历史数据，定期清理过时的数据可以减小数据量，提高查询性能。
7. **使用合适的数据库引擎：** 不同的数据库引擎对于分页查询的性能有不同的影响。根据具体的需求选择合适的数据库引擎。
8. **数据库分片：** 如果数据量非常巨大，可以考虑将数据库分成多个片，每个片存储一部分数据。这可以分散查询压力。
9. **异步加载：** 如果用户可以接受，可以使用异步加载的方式，让用户在等待数据加载时继续浏览其他内容。
10. **数据库优化：** 对于大规模数据集，数据库性能优化非常重要。确保数据库的硬件和配置都足够支持大规模查询。
### 大表查询如何优化?
**分库分表、读写分离以及缓存**
1. **合适的索引：** 确保查询中的列有适当的索引。索引可以加速数据检索。分析查询并确定哪些列被频繁用于过滤、排序或连接，然后为这些列创建索引。
2. **覆盖索引：** 考虑使用覆盖索引，这是一种包含了查询所需字段的索引。这可以减少数据库访问磁盘的次数，提高查询性能。
3. **避免全表扫描：** 避免在大表上执行全表扫描，这会对性能产生严重的影响。尽量使用索引或其他策略来缩小查询范围。
4. **分页查询：** 对于大表，避免一次性查询大量数据。使用分页查询，限制每次查询的结果行数，以减少数据传输和处理的负担。
5. **定期维护统计信息：** 定期更新表的统计信息，以确保查询优化器可以正确选择最佳执行计划。
6. **分区表：** 如果可能的话，将大表分成若干个分区，根据日期、范围或其他条件进行分区。这可以减小每个分区的大小，提高查询性能。
7. **使用汇总数据：** 对于报表查询或需要聚合数据的查询，可以使用汇总表或缓存已计算的结果，而不是每次都重新计算。
8. **查询重写：** 重新审视查询，并尝试通过不同的方式来表达查询，以获得更好的性能。有时，使用不同的连接顺序或条件可以改善查询性能。
9. **分析执行计划：** 使用数据库管理系统提供的工具来分析查询执行计划，以了解哪些步骤消耗了时间，从而进行有针对性的优化。
10. **垂直分割：** 如果表包含大量列，但每次查询只需要一部分列，可以考虑将表进行垂直分割，将不常用的列拆分到不同的表中。
11. **缓存：** 对于频繁查询的数据，可以考虑使用缓存，将查询结果存储在缓存中，以减轻数据库负载。
12. **使用数据库分片：** 对于极端大表，可以考虑使用数据库分片（Sharding）来水平划分数据，将不同数据存储在不同的物理数据库中，以分散负载。
13. **定期数据清理：** 删除不再需要的历史数据，以减小表的大小，提高查询性能。